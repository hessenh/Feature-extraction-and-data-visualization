{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1>Feature extraction subject P03 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('html',False)\n",
    "\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CHEST_X = path.relpath('data/P03_DATA_WINDOW/PO3_CHEST_X.csv')\n",
    "CHEST_Y = path.relpath('data/P03_DATA_WINDOW/PO3_CHEST_Y.csv')\n",
    "CHEST_Z = path.relpath('data/P03_DATA_WINDOW/PO3_CHEST_Z.csv')\n",
    "\n",
    "THIGH_X = path.relpath('data/P03_DATA_WINDOW/PO3_THIGH_X.csv')\n",
    "THIGH_Y = path.relpath('data/P03_DATA_WINDOW/PO3_THIGH_Y.csv')\n",
    "THIGH_Z = path.relpath('data/P03_DATA_WINDOW/PO3_THIGH_Z.csv')\n",
    "\n",
    "LABEL = path.relpath('data/P03_DATA_WINDOW/P03_LABEL_L.csv')\n",
    "\n",
    "df_chest_x = pd.read_csv(CHEST_X, header=None, sep='\\,')\n",
    "df_chest_y = pd.read_csv(CHEST_Y, header=None, sep='\\,')\n",
    "df_chest_z = pd.read_csv(CHEST_Z, header=None, sep='\\,')\n",
    "\n",
    "df_thigh_x = pd.read_csv(THIGH_X, header=None, sep='\\,')\n",
    "df_thigh_y = pd.read_csv(THIGH_Y, header=None, sep='\\,')\n",
    "df_thigh_z = pd.read_csv(THIGH_Z, header=None, sep='\\,')\n",
    "\n",
    "df_label = pd.read_csv(LABEL, header=None, sep='\\ ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36180 31115\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print len(df_chest_x), len(df_thigh_x)\n",
    "print min(3,4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Zero crossing rate</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.411764705882\n"
     ]
    }
   ],
   "source": [
    "#Zero crossing\n",
    "def zero_crossing_rate(l,size):\n",
    "    return len(np.where(np.diff(np.sign(l)))[0])*1.0 / size\n",
    "\n",
    "a = [1, 2, 1, 1, -3, -4, 7, 8, 9, 10, -2, 1, -3, 5, 6, 7, -10]\n",
    "print zero_crossing_rate(a,17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Correlation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def correlation(data_frame_one, data_frame_two):\n",
    "    return data_frame_one.corr(data_frame_two)\n",
    "\n",
    "#df_chest_x_frame = df_chest_x.iloc[100]\n",
    "#df_chest_y_frame = df_chest_y.iloc[100]\n",
    "#print correlation(df_chest_y_frame, df_chest_x_frame)\n",
    "\n",
    "def extractCorrelation(data_frame_one, data_frame_two, start, size):\n",
    "    res = []\n",
    "    \n",
    "    for i in range(start, start + size):\n",
    "        res.append(correlation(data_frame_one.iloc[i], data_frame_two.iloc[i]))\n",
    "        \n",
    "    return pd.DataFrame(np.array(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Energy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sumOfSqr(axis):\n",
    "    l = []\n",
    "    for i in axis:\n",
    "        l.append(float(i))\n",
    "    mean = sum(l)/len(l)\n",
    "    s = 0\n",
    "    for i in l:\n",
    "        s += (i-mean)**2\n",
    "    return s**0.5\n",
    "    \n",
    "def extractEnergy(x ,y ,z ,n_sample ,start, size):\n",
    "    res = []\n",
    "    for i in range(start, start + size):\n",
    "        e = sumOfSqr(x.iloc[i]) + sumOfSqr(y.iloc[i]) + sumOfSqr(z.iloc[i])\n",
    "        e = e/ 3\n",
    "        e = e / n_sample\n",
    "        res.append(e)\n",
    "        \n",
    "    return pd.DataFrame(np.array(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Root mean squere</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_chest_x_frame = df_chest_x.iloc[100]\n",
    "#print np.sqrt(df_chest_x_frame.dot(df_chest_x_frame)*1.0/df_chest_x_frame.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2> Function to extract basic information for each window </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "http://pandas.pydata.org/pandas-docs/stable/api.html#id5\n",
    "Information about mean, median... \n",
    "'''\n",
    "\n",
    "def extract(method, data_frame, start, size):\n",
    "    res = []\n",
    "    for i in range(start, start + size):\n",
    "        \n",
    "        if method == 'mean':\n",
    "            res.append(data_frame.iloc[i].mean())\n",
    "        elif method == 'median':\n",
    "            res.append(data_frame.iloc[i].median())\n",
    "        elif method == 'max':\n",
    "            res.append(data_frame.iloc[i].max())\n",
    "        elif method == 'min':\n",
    "            res.append(data_frame.iloc[i].min())\n",
    "        elif method == 'std':\n",
    "            res.append(data_frame.iloc[i].std())\n",
    "        elif method == 'zero-crossing':\n",
    "            res.append(zero_crossing_rate(data_frame.iloc[i],size))\n",
    "        elif method == 'rms':\n",
    "            res.append(np.sqrt(data_frame.iloc[i].dot(data_frame.iloc[i])*1.0/size))\n",
    "        else:\n",
    "            res.append(data_frame.iloc[i])\n",
    "        \n",
    "    return pd.DataFrame(np.array(res))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_feature(feature_type,df_x,df_y,df_z,path,sensor):\n",
    "    start=0\n",
    "    size=min(len(df_chest_x), len(df_thigh_x))-1 \n",
    "    \n",
    "    \n",
    "\n",
    "    FEATURES = path\n",
    "    try:\n",
    "        df_features = pd.read_csv(FEATURES, sep='\\,')\n",
    "        \n",
    "        l = []\n",
    "        # Get all the featues already computed\n",
    "        for i in df_features.columns.values:\n",
    "            n = i.split(\"_\")\n",
    "            n = n[0] + '_' + n[1]\n",
    "            l.append(n)\n",
    "        \n",
    "        # Create the string format of the feature: feature and sensor\n",
    "        t = feature_type + \"_\" + sensor\n",
    "\n",
    "        \n",
    "        if t not in l:\n",
    "            print \"Adding feature: \", t\n",
    "            # This is for all axis\n",
    "            if feature_type == \"energy\":\n",
    "                df_sensor_feature = extractEnergy(df_x,df_y,df_z,len(df_x.iloc[0].values), start, size)\n",
    "                df_sensor_feature.columns = [feature_type + '_' + sensor ]\n",
    "                \n",
    "                df_features= pd.concat([df_features, df_sensor_feature],axis=1)\n",
    "                \n",
    "            elif feature_type == \"correlation\":\n",
    "                df_correlation_xy = extractCorrelation(df_x, df_y, start, size)\n",
    "                df_correlation_xy.columns = [feature_type + '_' + sensor + \"_xy\"]\n",
    "                \n",
    "                df_correlation_xz = extractCorrelation(df_x, df_z, start, size)\n",
    "                df_correlation_xz.columns = [feature_type + '_' + sensor + \"_xz\"]\n",
    "                \n",
    "                df_correlation_yz = extractCorrelation(df_y, df_z, start, size)\n",
    "                df_correlation_yz.columns = [feature_type + '_' + sensor + \"_yz\"]\n",
    "                \n",
    "                df_features= pd.concat([df_features, df_correlation_xy,df_correlation_xz, df_correlation_yz],axis=1)\n",
    "            # Only for one axis\n",
    "            else:\n",
    "                df_x_feature = extract(feature_type,df_x,start,size)\n",
    "                df_x_feature.columns = [feature_type + '_' + sensor +  '_x' ]\n",
    "                df_y_feature = extract(feature_type,df_y,start,size)\n",
    "                df_y_feature.columns = [feature_type + '_' + sensor +  '_y']\n",
    "                df_z_feature= extract(feature_type,df_z,start,size)\n",
    "                df_z_feature.columns = [feature_type + '_' + sensor +  '_z' ]\n",
    "                \n",
    "                df_features= pd.concat([df_features, df_x_feature,df_y_feature, df_z_feature],axis=1)\n",
    "            \n",
    "        else:\n",
    "            print t, \" is already computed\"\n",
    "           \n",
    "        \n",
    "        \n",
    "    except IOError:\n",
    "        print 'file is empty'\n",
    "        if feature_type == \"energy\":\n",
    "            df_sensor_feature = extractEnergy(df_x,df_y,df_z,len(df_x.iloc[0].values), start, size)\n",
    "            df_sensor_feature.columns = [feature_type + '_' + sensor ]\n",
    "\n",
    "            df_features= df_sensor_feature\n",
    "            \n",
    "        elif feature_type == \"correlation\":\n",
    "                df_correlation_xy = extractCorrelation(df_x, df_y, start, size)\n",
    "                df_correlation_xy.columns = [feature_type + '_' + sensor + \"_xy\"]\n",
    "                \n",
    "                df_correlation_xz = extractCorrelation(df_x, df_z, start, size)\n",
    "                df_correlation_xz.columns = [feature_type + '_' + sensor + \"_xz\"]\n",
    "                \n",
    "                df_correlation_yz = extractCorrelation(df_y, df_z, start, size)\n",
    "                df_correlation_yz.columns = [feature_type + '_' + sensor + \"_yz\"]\n",
    "                \n",
    "                df_features= pd.concat([df_correlation_xy,df_correlation_xz, df_correlation_yz],axis=1)\n",
    "        else:\n",
    "            df_x_feature = extract(feature_type,df_x,start,size)\n",
    "            df_x_feature.columns = [feature_type + '_' + sensor +  '_x' ]\n",
    "            df_y_feature = extract(feature_type,df_y,start,size)\n",
    "            df_y_feature.columns = [feature_type + '_' + sensor +  '_y']\n",
    "            df_z_feature= extract(feature_type,df_z,start,size)\n",
    "            df_z_feature.columns = [feature_type + '_' + sensor +  '_z' ]\n",
    "            \n",
    "            df_features= pd.concat([df_x_feature,df_y_feature, df_z_feature],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    df_features.to_csv(FEATURES, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_thigh  is already computed\n",
      "mean_chest  is already computed\n",
      "min_thigh  is already computed\n",
      "min_chest  is already computed\n",
      "max_thigh  is already computed\n",
      "max_chest  is already computed\n",
      "median_thigh  is already computed\n",
      "median_chest  is already computed\n",
      "std_thigh  is already computed\n",
      "std_chest  is already computed\n",
      "energy_thigh  is already computed\n",
      "energy_chest  is already computed\n",
      "zero-crossing_thigh  is already computed\n",
      "zero-crossing_chest  is already computed\n",
      "correlation_thigh  is already computed\n",
      "correlation_chest  is already computed\n",
      "Adding feature:  rms_thigh\n",
      "Adding feature:  rms_chest\n"
     ]
    }
   ],
   "source": [
    "path = path.relpath('data/FEATURES_P03.csv')\n",
    "features = ['mean', 'min', 'max', 'median','std', 'energy', 'zero-crossing', 'correlation', 'rms']\n",
    "\n",
    "\n",
    "for f in features:\n",
    "    add_feature(f, df_thigh_x, df_thigh_y, df_thigh_z, path, 'thigh')\n",
    "    add_feature(f, df_chest_x, df_chest_y, df_chest_z, path, 'chest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
